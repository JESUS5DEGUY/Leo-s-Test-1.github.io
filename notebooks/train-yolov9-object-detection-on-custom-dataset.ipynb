{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "history_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# How to Train YOLOv9 on a Custom Dataset\n",
        "---\n",
        "\n",
        "[![Roboflow](https://raw.githubusercontent.com/roboflow-ai/notebooks/main/assets/badges/roboflow-blogpost.svg)](https://blog.roboflow.com/train-yolov9-model/)\n",
        "[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/WongKinYiu/yolov9)\n",
        "[![YouTube](https://badges.aleen42.com/src/youtube.svg)](https://youtu.be/XHT2c8jT3Bc)\n",
        "[![arXiv](https://img.shields.io/badge/arXiv-2402.13616-b31b1b.svg)](https://arxiv.org/pdf/2402.13616.pdf)"
      ],
      "metadata": {
        "id": "DQjdUKvQigN2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Before you start\n",
        "\n",
        "Let's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`."
      ],
      "metadata": {
        "id": "m09A8n4djDwY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5hX88yficL7",
        "outputId": "c1ef5bcd-eaa9-448a-8cd3-558c1d32765f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Mar  5 02:08:43 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   60C    P8             13W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}/yolov9\n",
        "\n",
        "!python train.py \\\n",
        "--batch 16 --epochs 25 --img 640 --device 0 --min-items 0 --close-mosaic 15 \\\n",
        "--data {dataset.location}/data.yaml \\\n",
        "--weights {HOME}/weights/gelan-c.pt \\\n",
        "--cfg models/detect/gelan-c.yaml \\\n",
        "--hyp hyp.scratch-high.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c12db2b-b823-4e1a-f200-a689ff577e79",
        "id": "n0NG1gThdSOM"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/yolov9'\n",
            "/content\n",
            "python3: can't open file '/content/train.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** To make it easier for us to manage datasets, images and models we create a `HOME` constant."
      ],
      "metadata": {
        "id": "UTprsNjHja4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rowKDIT-jJ9k",
        "outputId": "3bae6da0-cffb-40b0-846b-eb069c5443ca"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clone and Install"
      ],
      "metadata": {
        "id": "qWRGGT7Zjjbq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** YOLOv9 is very new. At the moment, we recommend using a fork of the main repository. The `detect.py` script contains a bug that prevents inference. This bug is patched in the fork."
      ],
      "metadata": {
        "id": "9WyY-fboBLZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/SkalskiP/yolov9.git\n",
        "%cd yolov9\n",
        "!pip install -r requirements.txt -q"
      ],
      "metadata": {
        "id": "pixgo4qnjdoU",
        "outputId": "3fafb9e5-4278-4dfe-de15-fc611aaaf9c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov9'...\n",
            "remote: Enumerating objects: 325, done.\u001b[K\n",
            "remote: Total 325 (delta 0), reused 0 (delta 0), pack-reused 325 (from 1)\u001b[K\n",
            "Receiving objects: 100% (325/325), 2.25 MiB | 5.01 MiB/s, done.\n",
            "Resolving deltas: 100% (162/162), done.\n",
            "/content/yolov9\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m88.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** Let's install the [`roboflow`](https://pypi.org/project/roboflow) package, which we will use to download our dataset from [Roboflow Universe](https://universe.roboflow.com/)."
      ],
      "metadata": {
        "id": "bcx7KoNzqpgz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q roboflow"
      ],
      "metadata": {
        "id": "TPGqlohQqgAO",
        "outputId": "3ce250a7-2b1c-428b-f1be-9e037affec2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/83.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m83.1/83.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download model weights"
      ],
      "metadata": {
        "id": "X8oLIkX2l2P0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** In the YOLOv9 paper, versions `yolov9-s` and `yolov9-m` are also mentioned, but the weights for these models are not yet available in the YOLOv9 [repository](https://github.com/WongKinYiu/yolov9)."
      ],
      "metadata": {
        "id": "0FieRuZnB4wH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -P {HOME}/weights -q https://github.com/WongKinYiu/yolov9/releases/download/v0.1/yolov9-c.pt\n",
        "!wget -P {HOME}/weights -q https://github.com/WongKinYiu/yolov9/releases/download/v0.1/yolov9-e.pt\n",
        "!wget -P {HOME}/weights -q https://github.com/WongKinYiu/yolov9/releases/download/v0.1/gelan-c.pt\n",
        "!wget -P {HOME}/weights -q https://github.com/WongKinYiu/yolov9/releases/download/v0.1/gelan-e.pt"
      ],
      "metadata": {
        "id": "h7j3aUE7l1Je"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -la {HOME}/weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Au6np1JS8eRB",
        "outputId": "f0461af3-5482-4285-f3c3-8d72e4bd86b4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 402452\n",
            "drwxr-xr-x 2 root root      4096 Mar  5 02:10 .\n",
            "drwxr-xr-x 1 root root      4096 Mar  5 02:10 ..\n",
            "-rw-r--r-- 1 root root  51508261 Feb 18  2024 gelan-c.pt\n",
            "-rw-r--r-- 1 root root 117203713 Feb 18  2024 gelan-e.pt\n",
            "-rw-r--r-- 1 root root 103153312 Feb 18  2024 yolov9-c.pt\n",
            "-rw-r--r-- 1 root root 140217688 Feb 18  2024 yolov9-e.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download example data"
      ],
      "metadata": {
        "id": "Dg29vEyLkTDA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** If you want to run inference using your own file as input, simply upload image to Google Colab and update `SOURCE_IMAGE_PATH` with the path leading to your file."
      ],
      "metadata": {
        "id": "xIKNGnN2kcTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -P {HOME}/data -q https://media.roboflow.com/notebooks/examples/dog.jpeg"
      ],
      "metadata": {
        "id": "uUiPMLxmj4Ze"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SOURCE_IMAGE_PATH = f\"{HOME}/dog.jpeg\""
      ],
      "metadata": {
        "id": "hiqFDio2kX8i"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Detection with pre-trained COCO model"
      ],
      "metadata": {
        "id": "4dlfABN6m-LL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### gelan-c"
      ],
      "metadata": {
        "id": "6EPCiYcFComZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights {HOME}/weights/gelan-c.pt --conf 0.1 --source {HOME}/data/dog.jpeg --device 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzGyLetWoTWp",
        "outputId": "08d97b1a-1c86-49bf-98ed-eb2200e25b13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/weights/gelan-c.pt'], source=/content/data/dog.jpeg, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.1, iou_thres=0.45, max_det=1000, device=0, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 ğŸš€ 1e33dbb Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\n",
            "/content/yolov9/models/experimental.py:75: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n",
            "Fusing layers... \n",
            "Model summary: 467 layers, 25472640 parameters, 0 gradients, 102.8 GFLOPs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** By default, the results of each subsequent inference sessions are saved in `{HOME}/yolov9/runs/detect/`, in directories named `exp`, `exp2`, `exp3`, ... You can override this behavior by using the `--name` parameter."
      ],
      "metadata": {
        "id": "hflXfkBt3N0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "Image(filename=f\"{HOME}/yolov9/runs/detect/exp/dog.jpeg\", width=600)"
      ],
      "metadata": {
        "id": "sAE1P1BxpHYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## yolov9-e"
      ],
      "metadata": {
        "id": "FCEIP-jFCsRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights {HOME}/weights/yolov9-e.pt --conf 0.1 --source {HOME}/data/dog.jpeg --device 0"
      ],
      "metadata": {
        "id": "eEQALIFaCuoX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "Image(filename=f\"{HOME}/yolov9/runs/detect/exp2/dog.jpeg\", width=600)"
      ],
      "metadata": {
        "id": "llm4xIE_CyXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Authenticate and Download the Dataset"
      ],
      "metadata": {
        "id": "D7fZKrxsq_td"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** The dataset must be saved inside the `{HOME}/yolov9` directory, otherwise, the training will not succeed."
      ],
      "metadata": {
        "id": "J5yx2GkI2P7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}/yolov9"
      ],
      "metadata": {
        "id": "MyLpftfU2Q1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** In this tutorial, I will use the [football-players-detection](https://universe.roboflow.com/roboflow-jvuqo/football-players-detection-3zvbc) dataset. Feel free to replace it with your dataset in YOLO format or use another dataset available on [Roboflow Universe](https://universe.roboflow.com). Additionally, if you plan to deploy your model to Roboflow after training, make sure you are the owner of the dataset and that no model is associated with the version of the dataset you are going to training on."
      ],
      "metadata": {
        "id": "eosmGt89vMO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"DlEkffoY4nr0lpBGE54g\")\n",
        "project = rf.workspace(\"thefuture\").project(\"elo328-3d-printfailure-detector-lsauw\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"yolov9\")\n",
        ""
      ],
      "metadata": {
        "id": "4J3s_2_7p_gn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Custom Model"
      ],
      "metadata": {
        "id": "CTbGpF2IsZ24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}/yolov9\n",
        "\n",
        "!python train.py \\\n",
        "--batch 16 --epochs 25 --img 640 --device 0 --min-items 0 --close-mosaic 15 \\\n",
        "--data {dataset.location}/data.yaml \\\n",
        "--weights {HOME}/weights/gelan-c.pt \\\n",
        "--cfg models/detect/gelan-c.yaml \\\n",
        "--hyp hyp.scratch-high.yaml"
      ],
      "metadata": {
        "id": "N68Bdf4FsMYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Examine Training Results"
      ],
      "metadata": {
        "id": "fpCwjSUg2Mrw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** By default, the results of each subsequent training sessions are saved in `{HOME}/yolov9/runs/train/`, in directories named `exp`, `exp2`, `exp3`, ... You can override this behavior by using the `--name` parameter."
      ],
      "metadata": {
        "id": "rHsMq7wc3bve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls {HOME}/yolov9/runs/train/exp/"
      ],
      "metadata": {
        "id": "WslwgMAW2Euc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "Image(filename=f\"{HOME}/yolov9/runs/train/exp/results.png\", width=1000)"
      ],
      "metadata": {
        "id": "grirpuCstpZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "Image(filename=f\"{HOME}/yolov9/runs/train/exp/confusion_matrix.png\", width=1000)"
      ],
      "metadata": {
        "id": "qggEg7Hv1zJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "Image(filename=f\"{HOME}/yolov9/runs/train/exp/val_batch0_pred.jpg\", width=1000)"
      ],
      "metadata": {
        "id": "Xja2fjTl32Ml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validate Custom Model"
      ],
      "metadata": {
        "id": "ih1rk9O_4CYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}/yolov9\n",
        "\n",
        "!python val.py \\\n",
        "--img 640 --batch 32 --conf 0.001 --iou 0.7 --device 0 \\\n",
        "--data {dataset.location}/data.yaml \\\n",
        "--weights {HOME}/yolov9/runs/train/exp/weights/best.pt"
      ],
      "metadata": {
        "id": "XoZv8kNE4NxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference with Custom Model"
      ],
      "metadata": {
        "id": "qJJ5fiqT6mEq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py \\\n",
        "--img 1280 --conf 0.1 --device 0 \\\n",
        "--weights {HOME}/yolov9/runs/train/exp/weights/best.pt \\\n",
        "--source {dataset.location}/test/images"
      ],
      "metadata": {
        "id": "8vnrn9cwIsUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** Just like behore, the inference results have been saved in the appropriate directory inside `{HOME}/yolov9/runs/detect/`. Let's examine few of those results."
      ],
      "metadata": {
        "id": "WPbhTtVXtM4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "from IPython.display import Image, display\n",
        "\n",
        "for image_path in glob.glob(f'{HOME}/yolov9/runs/detect/exp3/*.jpg')[:2]:\n",
        "      display(Image(filename=image_path, width=600))"
      ],
      "metadata": {
        "id": "XoV4sGOKJPZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BONUS: Deploy YOLOv9 Model with Inference"
      ],
      "metadata": {
        "id": "EMTTVZU48DdJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** To deploy the model and display inference results, we will need two additional packages - [`inference`](https://pypi.org/project/inference) and [`supervision`](https://pypi.org/project/supervision). Let's install and import them!"
      ],
      "metadata": {
        "id": "QoDQAk5arRfm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q inference supervision"
      ],
      "metadata": {
        "id": "Xn6YWeaa8bdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import random\n",
        "import getpass\n",
        "\n",
        "import supervision as sv\n",
        "\n",
        "from inference import get_model\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "4BauaNyA8wrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** Before using your model in Inference, you first need to upload your weights to Roboflow Universe. Ensure to specify the correct `model_type` - `yolov9`, and that the project version matches the version of the dataset you used for training, denoted by `[1]`. In my case, it's `6`.\n",
        "\n",
        "![YOLOv9 Benchmark](https://storage.googleapis.com/com-roboflow-marketing/notebooks/examples/upload-roboflow-model.png)\n",
        "\n"
      ],
      "metadata": {
        "id": "wu0-mgYpskPY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "version.deploy(model_type=\"yolov9\", model_path=f\"{HOME}/yolov9/runs/train/exp\")"
      ],
      "metadata": {
        "id": "tV-BnNU-7_4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** Now we can download our model anywhere using the assigned `model_id` denoted by `[2]`. In my case `football-players-detection-3zvbc/6`. To download the model you will need your [`ROBOFLOW_API_KEY`](https://docs.roboflow.com/api-reference/authentication).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KH30xwvAx1nb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ROBOFLOW_API_KEY = getpass.getpass()\n",
        "\n",
        "model = get_model(model_id=\"football-players-detection-3zvbc/8\", api_key=ROBOFLOW_API_KEY)"
      ],
      "metadata": {
        "id": "bAB-5ZMM87w3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** Let's pick random image from our test subset and detect objects using newly fine-tuned model."
      ],
      "metadata": {
        "id": "5pGSLZ8Fz5qO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_paths = sv.list_files_with_extensions(\n",
        "    directory=f\"{dataset.location}/test/images\",\n",
        "    extensions=['png', 'jpg', 'jpeg']\n",
        ")\n",
        "image_path = random.choice(image_paths)\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "result = model.infer(image, confidence=0.1)[0]\n",
        "detections = sv.Detections.from_inference(result)"
      ],
      "metadata": {
        "id": "Aes2oRxi9Kpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** Finally, let's use supervision and [annotate](https://supervision.roboflow.com/develop/annotators/) our results."
      ],
      "metadata": {
        "id": "j8Xdr3Vp1uir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_annotator = sv.LabelAnnotator(text_color=sv.Color.BLACK)\n",
        "bounding_box_annotator = sv.BoundingBoxAnnotator()\n",
        "\n",
        "annotated_image = image.copy()\n",
        "annotated_image = bounding_box_annotator.annotate(scene=annotated_image, detections=detections)\n",
        "annotated_image = label_annotator.annotate(scene=annotated_image, detections=detections)\n",
        "\n",
        "sv.plot_image(annotated_image)"
      ],
      "metadata": {
        "id": "Kq0BKx1_-kAy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}